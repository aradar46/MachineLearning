{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "melPath= \"/home/arash/Documents/Dropbox/melb_data.csv\"\n",
    "melbData= pd.read_csv(melPath)\n",
    "df= pd.DataFrame(melbData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13580, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13580.000000</td>\n",
       "      <td>1.358000e+04</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13518.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>7130.000000</td>\n",
       "      <td>8205.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.937997</td>\n",
       "      <td>1.075684e+06</td>\n",
       "      <td>10.137776</td>\n",
       "      <td>3105.301915</td>\n",
       "      <td>2.914728</td>\n",
       "      <td>1.534242</td>\n",
       "      <td>1.610075</td>\n",
       "      <td>558.416127</td>\n",
       "      <td>151.967650</td>\n",
       "      <td>1964.684217</td>\n",
       "      <td>-37.809203</td>\n",
       "      <td>144.995216</td>\n",
       "      <td>7454.417378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.955748</td>\n",
       "      <td>6.393107e+05</td>\n",
       "      <td>5.868725</td>\n",
       "      <td>90.676964</td>\n",
       "      <td>0.965921</td>\n",
       "      <td>0.691712</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>3990.669241</td>\n",
       "      <td>541.014538</td>\n",
       "      <td>37.273762</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>4378.581772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.500000e+05</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.856822</td>\n",
       "      <td>144.929600</td>\n",
       "      <td>4380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.030000e+05</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3084.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802355</td>\n",
       "      <td>145.000100</td>\n",
       "      <td>6555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058305</td>\n",
       "      <td>10331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>433014.000000</td>\n",
       "      <td>44515.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "      <td>21650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rooms         Price      Distance      Postcode      Bedroom2  \\\n",
       "count  13580.000000  1.358000e+04  13580.000000  13580.000000  13580.000000   \n",
       "mean       2.937997  1.075684e+06     10.137776   3105.301915      2.914728   \n",
       "std        0.955748  6.393107e+05      5.868725     90.676964      0.965921   \n",
       "min        1.000000  8.500000e+04      0.000000   3000.000000      0.000000   \n",
       "25%        2.000000  6.500000e+05      6.100000   3044.000000      2.000000   \n",
       "50%        3.000000  9.030000e+05      9.200000   3084.000000      3.000000   \n",
       "75%        3.000000  1.330000e+06     13.000000   3148.000000      3.000000   \n",
       "max       10.000000  9.000000e+06     48.100000   3977.000000     20.000000   \n",
       "\n",
       "           Bathroom           Car       Landsize  BuildingArea    YearBuilt  \\\n",
       "count  13580.000000  13518.000000   13580.000000   7130.000000  8205.000000   \n",
       "mean       1.534242      1.610075     558.416127    151.967650  1964.684217   \n",
       "std        0.691712      0.962634    3990.669241    541.014538    37.273762   \n",
       "min        0.000000      0.000000       0.000000      0.000000  1196.000000   \n",
       "25%        1.000000      1.000000     177.000000     93.000000  1940.000000   \n",
       "50%        1.000000      2.000000     440.000000    126.000000  1970.000000   \n",
       "75%        2.000000      2.000000     651.000000    174.000000  1999.000000   \n",
       "max        8.000000     10.000000  433014.000000  44515.000000  2018.000000   \n",
       "\n",
       "          Lattitude    Longtitude  Propertycount  \n",
       "count  13580.000000  13580.000000   13580.000000  \n",
       "mean     -37.809203    144.995216    7454.417378  \n",
       "std        0.079260      0.103916    4378.581772  \n",
       "min      -38.182550    144.431810     249.000000  \n",
       "25%      -37.856822    144.929600    4380.000000  \n",
       "50%      -37.802355    145.000100    6555.000000  \n",
       "75%      -37.756400    145.058305   10331.000000  \n",
       "max      -37.408530    145.526350   21650.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Data Description\n",
    "The results show 8 numbers for each column in your original dataset. The first number, the count, shows how many rows have non-missing values.\n",
    "\n",
    "Missing values arise for many reasons. For example, the size of the 2nd bedroom wouldn't be collected when surveying a 1 bedroom house. We'll come back to the topic of missing data.\n",
    "\n",
    "The second value is the mean, which is the average. Under that, std is the standard deviation, which measures how numerically spread out the values are.\n",
    "\n",
    "To interpret the min, 25%, 50%, 75% and max values, imagine sorting each column from lowest to highest value. The first (smallest) value is the min. If you go a quarter way through the list, you'll find a number that is bigger than 25% of the values and smaller than 75% of the values. That is the 25% value (pronounced \"25th percentile\"). The 50th and 75th percentiles are defined analogously, and the max is the largest number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6196, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\n",
    "# We'll learn to handle missing values in a later tutorial.\n",
    "# Your Iowa data doesn't have missing values in the columns you use.\n",
    "# So we will take the simplest option for now, and drop houses from our data.\n",
    "# Don't worry about this much for now, though the code is:\n",
    "\n",
    "# dropna drops missing values (think of na as \"not available\")\n",
    "df = df.dropna(axis=0)\n",
    "# axis: {0 or 'index', 1 or 'columns'}, default 0\n",
    "# Determine if rows or columns which contain missing values are removed.\n",
    "\n",
    "# 0, or 'index': Drop rows which contain missing values.\n",
    "# 1, or 'columns': Drop columns which contain missing value.\n",
    "# how: {'any', 'all'}, default 'any'\n",
    "# Determine if row or column is removed from DataFrame, when we have at least one NA or all NA.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to select a subset of your data. The Pandas course covers these in more depth, but we will focus on two approaches for now.\n",
    "\n",
    "1. Dot notation, which we use to select the \"prediction target\"\n",
    "2. Selecting with a column list, which we use to select the \"features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting The Prediction Target¶\n",
    "\n",
    "You can pull out a variable with dot-notation. This single column is stored in a Series, which is broadly like a DataFrame with only a single column of data.\n",
    "\n",
    "We'll use the dot notation to select the column we want to predict, which is called the prediction target. By convention, the prediction target is called y. So the code we need to save the house prices in the Melbourne data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1035000.0\n",
       "2    1465000.0\n",
       "4    1600000.0\n",
       "6    1876000.0\n",
       "7    1636000.0\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting The Prediction Target\n",
    "y = df.Price\n",
    "y.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing \"Features\"¶\n",
    "\n",
    "The columns that are inputted into our model (and later used to make predictions) are called \"features.\" In our case, those would be the columns used to determine the home price. Sometimes, you will use all columns except the target as features. Other times you'll be better off with fewer features.\n",
    "\n",
    "For now, we'll build a model with only a few features. Later on you'll see how to iterate and compare models built with different features.\n",
    "\n",
    "We select multiple features by providing a list of column names inside brackets. Each item in that list should be a string (with quotes).\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_features = ['Rooms', 'Bathroom',\n",
    "                      'Landsize', 'Lattitude', 'Longtitude']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.931407</td>\n",
       "      <td>1.576340</td>\n",
       "      <td>471.006940</td>\n",
       "      <td>-37.807904</td>\n",
       "      <td>144.990201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>897.449881</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.099165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.164920</td>\n",
       "      <td>144.542370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-37.855438</td>\n",
       "      <td>144.926198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>-37.802250</td>\n",
       "      <td>144.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>-37.758200</td>\n",
       "      <td>145.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>-37.457090</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rooms     Bathroom      Landsize    Lattitude   Longtitude\n",
       "count  6196.000000  6196.000000   6196.000000  6196.000000  6196.000000\n",
       "mean      2.931407     1.576340    471.006940   -37.807904   144.990201\n",
       "std       0.971079     0.711362    897.449881     0.075850     0.099165\n",
       "min       1.000000     1.000000      0.000000   -38.164920   144.542370\n",
       "25%       2.000000     1.000000    152.000000   -37.855438   144.926198\n",
       "50%       3.000000     1.000000    373.000000   -37.802250   144.995800\n",
       "75%       4.000000     2.000000    628.000000   -37.758200   145.052700\n",
       "max       8.000000     8.000000  37000.000000   -37.457090   145.526350"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By convention, this data is called X.\n",
    "\n",
    "X = df[melbourne_features]\n",
    "X.describe()\n",
    "\n",
    "# Visually checking your data with these commands is an \n",
    "# important part of a data scientist's job. You'll frequently \n",
    "# find surprises in the dataset that deserve further inspection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Your Model\n",
    "\n",
    "You will use the `**scikit-learn library**` to create your models. When coding, this library is written as `**sklearn**`, as you will see in the sample code. \n",
    "\n",
    "Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames.\n",
    "\n",
    "#### The steps to building and using a model are:\n",
    "\n",
    "1. **Define:** What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n",
    "2. **Fit:** Capture patterns from provided data. This is the heart of modeling.\n",
    "3. **Predict:** Just what it sounds like\n",
    "4. **Evaluate:** Determine how accurate the model's predictions are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)\n",
    "#uild a decision tree regressor from the training set (X, y).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures you get the same results in each run. This is considered a good practice. You use any number, and model quality won't depend meaningfully on exactly what value you choose.\n",
    "\n",
    "We now have a fitted model that we can use to make predictions.\n",
    "\n",
    "In practice, you'll want to make predictions for new houses coming on the market rather than the houses we already have prices for. But we'll make predictions for the first few rows of the training data to see how the predict function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses:\n",
      "\n",
      "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "1      2       1.0     156.0   -37.8079    144.9934\n",
      "2      3       2.0     134.0   -37.8093    144.9944\n",
      "4      4       1.0     120.0   -37.8072    144.9941\n",
      "6      3       2.0     245.0   -37.8024    144.9993\n",
      "7      2       1.0     256.0   -37.8060    144.9954\n",
      "\n",
      "The predictions are\n",
      "\n",
      "[1035000. 1465000. 1600000. 1876000. 1636000.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Making predictions for the following 5 houses:\\n\")\n",
    "print(X.head())\n",
    "print(\"\\nThe predictions are\\n\")\n",
    "\n",
    "\n",
    "print(melbourne_model.predict(X.head()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to dataframe using pandas\n",
    "# select target prediction and name it y\n",
    "# select features for prediction and name it X\n",
    "    # select features by name\n",
    "    # list of features in a list\n",
    "    # X= df[features]\n",
    "# check the data with X.describe()\n",
    "# Build a model\n",
    "   # from sklearn.tree import DecisionTreeRegressor\n",
    "    # melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "    # random_state=1 is for reproducibility\n",
    "# Fit the model\n",
    "    # melbourne_model.fit(X, y)\n",
    "# Make predictions\n",
    "    # melbourne_model.predict(X)\n",
    "# Evaluate the model\n",
    "    # from sklearn.metrics import mean_absolute_error\n",
    "    # predicted_home_prices = melbourne_model.predict(X)\n",
    "    # mean_absolute_error(y, predicted_home_prices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will learn to use model validation to measure the quality of your model. Measuring model quality is the key to iteratively improving your models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n most (though not all) applications, the relevant measure of model quality is predictive accuracy. In other words, will the model's predictions be close to what actually happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'd first need to summarize the model quality into an understandable way. If you compare predicted and actual home values for 10,000 houses, you'll likely find mix of good and bad predictions. Looking through a list of 10,000 predicted and actual values would be pointless. We need to summarize this into a single metric.\n",
    "\n",
    "There are many metrics for summarizing model quality, but we'll start with one called Mean Absolute Error (also called MAE). Let's break down this metric starting with the last word, error.\n",
    "\n",
    "The prediction error for each house is:\n",
    "\n",
    "error=actual−predicted\n",
    "\n",
    "So, if a house cost $150,000 and you predicted it would cost $100,000 the error is $50,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the MAE metric, we take the absolute value of each error. This converts each error to a positive number. We then take the average of those absolute errors. This is our measure of model quality. In plain English, it can be said as\n",
    "\n",
    "On average, our predictions are off by about X.\n",
    "\n",
    "To calculate MAE, we first need a model. That is built in a hidden cell below, which you can review by clicking the code button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115.7467183128902"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272495.14288788463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,\n",
    " random_state=0)\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "# Fit model\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# get predicted prices on validation data\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First in-sample predictions:    [208500. 181500. 223500. 140000. 250000.]\n",
      "Actual target values for homes: [208500, 181500, 223500, 140000, 250000]\n",
      "\n",
      "Mean Absolute Error in Validation Data:  29263.342465753423\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read the file\n",
    "filepath = \"/home/arash/Documents/Dropbox/iowa.csv\"\n",
    "iowa = pd.read_csv(filepath)\n",
    "iowa = pd.DataFrame(iowa)\n",
    "iowa.columns\n",
    "\n",
    "# choose the target variable\n",
    "y = iowa.SalePrice\n",
    "\n",
    "# choose the features\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', ]\n",
    "X = iowa[features]\n",
    "\n",
    "# fit the model\n",
    "iowaModel = DecisionTreeRegressor(random_state=1)\n",
    "iowaModel.fit(X, y)\n",
    "\n",
    "# predict\n",
    "pred = iowaModel.predict(X)\n",
    "\n",
    "print(\"First in-sample predictions:   \", iowaModel.predict(X.head()))\n",
    "print(\"Actual target values for homes:\", y.head().tolist())\n",
    "\n",
    "# split the data into training and validation data for both\n",
    "# features and target # The split is based on a random number generator.\n",
    "#  Supplying a numeric value to the random_state argument guarantees\n",
    "#  we get the same split every time we run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "# Step 2: Specify and Fit the Model\n",
    "# Create a DecisionTreeRegressor model and fit it to the relevant data.\n",
    "# Set random_state to 1 again when creating the model.\n",
    "iowaModel = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# fit the model\n",
    "iowaModel.fit(train_X, train_y)\n",
    "\n",
    "#step 3: Make Predictions with Validation data\n",
    "val_predictions = iowaModel.predict(val_X)\n",
    "\n",
    "#step 4: Calculate the Mean Absolute Error in Validation Data\n",
    "#firs value is the actual value and the second value is the predicted value\n",
    "val_mae = mean_absolute_error(val_y, val_predictions)\n",
    "print(\"\\nMean Absolute Error in Validation Data: \", val_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data: the data used to fit the model\n",
    "# validation data: the data used to make predictions and evaluate the model\n",
    "# test data: the data used to check the accuracy of the model on new data\n",
    "# The reason for the distinction between training and validation data is that\n",
    "#  the validation data is used to compare the accuracy of different models.\n",
    "#  If a model performs well on the training data but poorly on the validation data,\n",
    "#  the model is overfitting. Overfitting occurs when a model matches the training data\n",
    "#  almost perfectly, but does poorly in validation and other new data.\n",
    "#  This is a sign that the model will likely do poorly in production.\n",
    "#  We want to pick a model that does well in both training and validation data.\n",
    "#  If a model performs well on both training and validation data, it is said to\n",
    "#  generalize well. This means that we can feel confident making predictions with\n",
    "#  that model on new data.\n",
    "#  The test data provides a final check on how a model will perform in production.\n",
    "#  It is important to test your model on data that was not used to fit the model.\n",
    "#  This is the only way to know if your model will truly generalize.\n",
    "#  If the model performs well on the training data but poorly on the test data,\n",
    "#  it is likely that the model is overfitting.\n",
    "#  If the model performs poorly in both training and test data, it is likely\n",
    "#  that the model is underfitting.\n",
    "#  If the model performs well on the test data but poorly on the training data,\n",
    "#  it is likely that the model is overfitting.\n",
    "#  If the model performs well on both the training and test data, it is likely\n",
    "#  that the model is a good fit.\n",
    "\n",
    "# How to improve the model\n",
    "# 1. Use a different model\n",
    "# 2. Improve the quality of the data\n",
    "# 3. Tune the hyperparameters of the model\n",
    "    # Hyperparameters are values that can be specified before the model is fit.\n",
    "    #  They specify how the model will be fit to the training data.\n",
    "    #  For example, the max_leaf_nodes hyperparameter for a decision tree model\n",
    "    #  specifies the maximum number of leaves in the tree.\n",
    "    #  The model will stop splitting nodes when the number of leaves reaches this value.\n",
    "    #  The max_leaf_nodes hyperparameter is an example of a model-specific hyperparameter.\n",
    "    #  Different models have different hyperparameters.\n",
    "    #  The hyperparameters of a model are specified before the model is fit.\n",
    "    #  The model is fit to the training data using the hyperparameters.\n",
    "\n",
    "# 4. Get more data\n",
    "# 5. Get more features\n",
    "\n",
    "# Types of models\n",
    "# 1. Decision Tree\n",
    "# 2. Random Forest\n",
    "# 3. Gradient Boosting\n",
    "# 4. Support Vector Machine\n",
    "# 5. Neural Network\n",
    "# 6. Linear Regression\n",
    "# 7. Logistic Regression\n",
    "# 8. K-Nearest Neighbors\n",
    "# 9. Naive Bayes\n",
    "# 10. Stochastic Gradient Descent\n",
    "# 11. Gaussian Process\n",
    "# 12. ....\n",
    "\n",
    "# 1. Decision Tree Model: Decision trees are a type of supervised learning algorithm\n",
    "#  that can be used for both classification and regression tasks.\n",
    "#  The goal is to create a model that predicts the value of a target variable by\n",
    "#  learning simple decision rules inferred from the data features.\n",
    "#  The decision tree algorithm works as follows:\n",
    "#  1. The algorithm starts with the entire training dataset.\n",
    "#  2. The algorithm splits the dataset into two subsets based on the value of a\n",
    "#     single feature. The feature and the value are chosen in a way that reduces\n",
    "#     the uncertainty of the target variable.\n",
    "#  3. The algorithm splits the subsets using the same logic.\n",
    "#  4. The process continues until a stopping criterion is reached.\n",
    "#  5. The final result is a tree with decision nodes and leaf nodes.\n",
    "#  The decision nodes (e.g., color = green) are used to split the data.\n",
    "#  The leaf nodes (e.g., price = high) are used to make predictions.\n",
    "#  The decision tree algorithm is a greedy algorithm.\n",
    "#  This means that it makes the best possible split at each step.\n",
    "#  The best possible split is the one that reduces the uncertainty of the target\n",
    "#  variable the most.\n",
    "#  The decision tree algorithm is a non-parametric model.\n",
    "#  This means that the model structure is determined from the data.\n",
    "#  The decision tree algorithm is a white box model.\n",
    "#  This means that the model is interpretable.\n",
    "#  The model can be visualized and the results can be explained.\n",
    "#  The decision tree algorithm is a relatively fast algorithm.\n",
    "#  This means that it can be used to train large datasets.\n",
    "#  The decision tree algorithm is a relatively simple algorithm.\n",
    "#  This means that it is easy to understand and explain.\n",
    "#  The decision tree algorithm is a relatively unstable algorithm.\n",
    "#  This means that small changes in the data can result in a completely different\n",
    "#  tree being generated.\n",
    "#  The decision tree algorithm is a relatively biased algorithm.\n",
    "#  This means that it tends to overfit the data.\n",
    "\n",
    "# how to avoid overfitting\n",
    "# 1. Use cross-validation\n",
    "# 2. Use a more powerful model\n",
    "# 3. Gather more training data\n",
    "# 4. Reduce the complexity of the model\n",
    "# 5. Use regularization\n",
    "# 6. Use ensembling\n",
    "\n",
    "\n",
    "# how to perform cross-validation\n",
    "# 1. Split the training data into k subsets\n",
    "# 2. Train the model on k-1 subsets\n",
    "# 3. Evaluate the model on the remaining subset\n",
    "# 4. Repeat steps 2 and 3 k times\n",
    "# 5. The final result is the average of the k evaluation scores\n",
    "\n",
    "\n",
    "#how to perform machine learning\n",
    "# 1. Define the problem\n",
    "# 2. Prepare the data\n",
    "# 3. Choose a model\n",
    "        # 3.1. Choose a model class\n",
    "        # 3.2. Choose model hyperparameters\n",
    "# 4. Train the model:\n",
    "        # 4.1. Fit the model to the training data\n",
    "        # 4.2. Use the model to make predictions\n",
    "# 5. Evaluate the model\n",
    "        # 5.1. Determine if the predictions are good\n",
    "        # 5.2. If the predictions are not good, go back to step 3\n",
    "\n",
    "# 6. Tune the model\n",
    "        # 6.1. Choose a different model class\n",
    "        # 6.2. Choose different model hyperparameters\n",
    "        # 6.3. Gather more training data\n",
    "        # 6.4. Gather more features\n",
    "        # 6.5. Reduce the complexity of the model\n",
    "        # 6.6. Use regularization\n",
    "        # 6.7. Use ensembling\n",
    "\n",
    "# 7. Make predictions\n",
    "    # 7.1. Gather new data\n",
    "    # 7.2. Prepare the data\n",
    "    # 7.3. Use the trained model to make predictions on the new data\n",
    "\n",
    "# 8. Deploy, monitor, and maintain the model\n",
    "\n",
    "\n",
    "# how to learn machine learning\n",
    "# 1. Learn the math and statistics\n",
    "        # 1.1. Linear algebra\n",
    "        # 1.2. Calculus\n",
    "        # 1.3. Probability and statistics\n",
    "        # 1.4. Optimization\n",
    "        # 1.5. Information theory\n",
    "        # 1.6. Numerical methods\n",
    "        # 1.7. Machine learning theory\n",
    "        \n",
    "# 2. Learn the programming\n",
    "        # 2.1. Python\n",
    "        # 2.2. R\n",
    "        # 2.3. SQL\n",
    "\n",
    "# 3. Learn the machine learning\n",
    "        # 3.1. Supervised learning\n",
    "        # 3.2. Unsupervised learning\n",
    "        # 3.3. Reinforcement learning\n",
    "        # 3.4. Deep learning\n",
    "        # 3.5. Natural language processing\n",
    "        # 3.6. Computer vision\n",
    "        # 3.7. Recommender systems\n",
    "        # 3.8. Time series analysis\n",
    "        # 3.9. Bayesian methods\n",
    "        # 3.10. Genetic algorithms\n",
    "        # 3.11. Graphical models\n",
    "        # 3.12. Dimensionality reduction\n",
    "        # 3.13. Clustering\n",
    "        # 3.14. Model selection and evaluation\n",
    "        # 3.15. Feature engineering\n",
    "        # 3.16. Model interpretation\n",
    "        # 3.17. Model deployment\n",
    "        # 3.18. Model monitoring and maintenance\n",
    "\n",
    "# 4. Learn the domain\n",
    "        # 4.1. Business\n",
    "        # 4.2. Finance\n",
    "        # 4.3. Medicine\n",
    "        # 4.4. Biology\n",
    "        # 4.5. Chemistry\n",
    "        # 4.6. Physics\n",
    "        # 4.7. Engineering\n",
    "        # 4.8. Computer science\n",
    "        # 4.9. ........\n",
    "# 5. Learn the tools\n",
    "        # 5.1. Jupyter notebooks: Jupyter notebooks are a web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text.\n",
    "        # 5.2. Git: version control\n",
    "        # 5.3. Docker\n",
    "        # 5.4. Kubernetes: Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n",
    "        # 5.5. AWS: S3, EC2, EMR, Lambda, SageMaker, Redshift, DynamoDB, RDS, etc.\n",
    "        # 5.6. GCP: Google Cloud Platform\n",
    "        # 5.7. Azure: Microsoft Azure Cloud Platform (formerly Windows Azure) is a cloud computing platform and infrastructure created by Microsoft for building, testing, deploying, and managing applications and services\n",
    "        # 5.8. and more\n",
    "# 6. Learn the best practices\n",
    "        # 6.1. Data science best practices\n",
    "        # 6.2. Machine learning best practices\n",
    "        # 6.3. Software engineering best practices\n",
    "        # 6.4. and more\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b749fea7189503fc5ff9ab5abeb55c57c1e17fc001ffc93118531b49495b7ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
